{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-reload frequently changed files\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport utils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from altair_saver import save\n",
    "from os.path import join\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "from web import for_website\n",
    "\n",
    "from constants import COLUMNS, DATA_AGGREGATE_TYPES\n",
    "from utils import (\n",
    "    read_combined_daily_counts_df, read_combined_by_country_daily_counts_df, read_combined_by_site_daily_counts_df,\n",
    "    apply_theme, get_country_color_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Common info that should be defined everytime before rendering visualizations\n",
    "\"\"\"\n",
    "SITES = read_combined_by_site_daily_counts_df()[COLUMNS.SITE_ID].unique()\n",
    "\n",
    "# Titles\n",
    "NUM_SITES = len(SITES)\n",
    "DATA_DATE = \"2020-04-11\"\n",
    "VIS_DATE = \"2020-04-12\"\n",
    "SUBTITLE = f\"Data as of {DATA_DATE} | {NUM_SITES} Sites | Plots generated on {VIS_DATE}\"\n",
    "\n",
    "country_color_map = get_country_color_map()\n",
    "\n",
    "min_date = datetime.datetime(2020, 1, 28)\n",
    "max_date = datetime.datetime(2020, 3, 30)\n",
    "\n",
    "# Countries have different ids in the JHU data than in the 4CE data\n",
    "country_map = {\n",
    "    \"US\": \"USA\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"category\"\n",
    "\n",
    "def preprocess_daily_df(df_dc):\n",
    "    # Adapted from 02_daily_counts_altair.ipynb\n",
    "\n",
    "    # Wide to long\n",
    "    df_dc = pd.melt(df_dc, id_vars=[\n",
    "        COLUMNS.SITE_ID, COLUMNS.DATE,\n",
    "        COLUMNS.MASKED_UPPER_BOUND_NEW_POSITIVE_CASES,\n",
    "        COLUMNS.MASKED_UPPER_BOUND_PATIENTS_IN_ICU,\n",
    "        COLUMNS.MASKED_UPPER_BOUND_NEW_DEATHS,\n",
    "        COLUMNS.UNMASKED_SITES_NEW_POSITIVE_CASES,\n",
    "        COLUMNS.UNMASKED_SITES_PATIENTS_IN_ICU,\n",
    "        COLUMNS.UNMASKED_SITES_NEW_DEATHS,\n",
    "        COLUMNS.MASKED_SITES_NEW_POSITIVE_CASES,\n",
    "        COLUMNS.MASKED_SITES_PATIENTS_IN_ICU,\n",
    "        COLUMNS.MASKED_SITES_NEW_DEATHS\n",
    "    ])\n",
    "    df_dc = df_dc.rename(columns={\"variable\": CATEGORY, \"value\": COLUMNS.NUM_PATIENTS})\n",
    "\n",
    "    # Leave only the 'upper' and 'under' values for the certain 'category' only\n",
    "    for c in [COLUMNS.NEW_POSITIVE_CASES, COLUMNS.PATIENTS_IN_ICU, COLUMNS.NEW_DEATHS]:\n",
    "        filter_c = df_dc[CATEGORY] == c\n",
    "        df_dc.loc[filter_c, \"upper\"] = df_dc.loc[filter_c, COLUMNS.NUM_PATIENTS] + df_dc.loc[filter_c, \"masked_upper_bound_\" + c]\n",
    "        df_dc.loc[filter_c, \"under\"] = df_dc.loc[filter_c, COLUMNS.NUM_PATIENTS]\n",
    "        df_dc.loc[filter_c, COLUMNS.NUM_PATIENTS] = df_dc.loc[filter_c, COLUMNS.NUM_PATIENTS] + df_dc.loc[filter_c, \"masked_upper_bound_\" + c] / 2.0\n",
    "        \n",
    "        # Add num of sites\n",
    "        df_dc.loc[filter_c, COLUMNS.NUM_SITES] = df_dc[\"unmasked_sites_\" + c] + df_dc[\"masked_sites_\" + c]\n",
    "\n",
    "    # Drop unused columns\n",
    "    df_dc = df_dc.drop(columns=[\n",
    "        COLUMNS.MASKED_UPPER_BOUND_NEW_POSITIVE_CASES,\n",
    "        COLUMNS.MASKED_UPPER_BOUND_PATIENTS_IN_ICU,\n",
    "        COLUMNS.MASKED_UPPER_BOUND_NEW_DEATHS,\n",
    "        COLUMNS.UNMASKED_SITES_NEW_POSITIVE_CASES,\n",
    "        COLUMNS.UNMASKED_SITES_PATIENTS_IN_ICU,\n",
    "        COLUMNS.UNMASKED_SITES_NEW_DEATHS,\n",
    "        COLUMNS.MASKED_SITES_NEW_POSITIVE_CASES,\n",
    "        COLUMNS.MASKED_SITES_PATIENTS_IN_ICU,\n",
    "        COLUMNS.MASKED_SITES_NEW_DEATHS\n",
    "    ])\n",
    "    \n",
    "    return df_dc\n",
    "\n",
    "# Read files\n",
    "df_dc = preprocess_daily_df(read_combined_by_country_daily_counts_df())\n",
    "\n",
    "# Remove zero num_sites\n",
    "df_dc = df_dc[df_dc[COLUMNS.NUM_SITES] != 0]\n",
    "\n",
    "# In this notebook we are only concerned with the change in \"New positive cases\"\n",
    "for_category = \"new_positive_cases\"\n",
    "\n",
    "df_dc = df_dc.loc[df_dc[\"category\"] == for_category]\n",
    "df_dc = df_dc.rename(columns={\"siteid\": \"country\", \"num_patients\": \"count\"})\n",
    "\n",
    "df_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only need the JHU data for the countries that exist in the 4CE data.\n",
    "unique_countries = df_dc[\"country\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date strings into date objects.\n",
    "def convert_date(date_str):\n",
    "    try:\n",
    "        return dateutil.parser.parse(date_str)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the JHU data to obtain normalized change values.\n",
    "jhu_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/dcd4181613f512a6f75249fc77b63286aebe7271/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
    "jhu_df = pd.read_csv(jhu_url)\n",
    "\n",
    "jhu_df = jhu_df.rename(columns={\"Country/Region\": \"country\", \"Province/State\": \"state\"})\n",
    "jhu_df = jhu_df.drop(columns=[\"Lat\", \"Long\"])\n",
    "\n",
    "jhu_df[\"country\"] = jhu_df[\"country\"].apply(lambda c: country_map[c] if c in country_map else c)\n",
    "jhu_df = jhu_df.loc[jhu_df[\"country\"].isin(unique_countries)]\n",
    "jhu_df = jhu_df.loc[~pd.notna(jhu_df[\"state\"])]\n",
    "jhu_df = jhu_df.drop(columns=[\"state\"])\n",
    "\n",
    "jhu_df = jhu_df.melt(id_vars=[\"country\"], var_name=\"date\", value_name=\"cumulative_count\")\n",
    "\n",
    "jhu_df[\"date\"] = jhu_df[\"date\"].astype(str)\n",
    "jhu_df[\"date\"] = jhu_df[\"date\"].apply(convert_date)\n",
    "jhu_df = jhu_df.sort_values(by=\"date\", ascending=True)\n",
    "jhu_df = jhu_df.loc[(jhu_df[\"date\"] >= min_date) & (jhu_df[\"date\"] <= max_date)]\n",
    "\n",
    "\n",
    "jhu_roc_df = pd.DataFrame(index=[], data=[], columns=[\"country\", \"date\", \"cumulative_count\"])\n",
    "for country, country_df in jhu_df.groupby(\"country\"):\n",
    "    country_df = country_df.copy()\n",
    "    country_df[\"change\"] = np.concatenate((np.array([np.nan]), np.diff(country_df[\"cumulative_count\"].values)))\n",
    "    country_df[\"cumulative_count\"] = country_df[\"cumulative_count\"].replace(0, np.nan)\n",
    "    \n",
    "    cumulative_count_max = country_df[\"cumulative_count\"].max()\n",
    "    \n",
    "    country_df[\"change\"] = country_df[\"change\"] / cumulative_count_max\n",
    "\n",
    "    jhu_roc_df = jhu_roc_df.append(country_df, ignore_index=True)\n",
    "jhu_roc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the 4CE data to obtain normalized change values.\n",
    "df_dc = df_dc.loc[df_dc[\"category\"] == for_category]\n",
    "df_dc[\"date\"] = df_dc[\"date\"].astype(str)\n",
    "df_dc[\"date\"] = df_dc[\"date\"].apply(convert_date)\n",
    "df_dc = df_dc.sort_values(by=\"date\", ascending=True)\n",
    "df_dc = df_dc.loc[(df_dc[\"date\"] >= min_date) & (df_dc[\"date\"] <= max_date)]\n",
    "\n",
    "dc_roc_df = pd.DataFrame(index=[], data=[], columns=[\"country\", \"date\", \"count\"])\n",
    "for country, country_df in df_dc.groupby(\"country\"):\n",
    "    country_df = country_df.copy()\n",
    "    country_df[\"cumulative_count\"] = np.cumsum(country_df[\"count\"].values)\n",
    "    country_df[\"cumulative_count\"] = country_df[\"cumulative_count\"].replace(0, np.nan)\n",
    "    \n",
    "    country_df[\"cumulative_upper\"] = np.cumsum(country_df[\"upper\"].values)\n",
    "    country_df[\"cumulative_upper\"] = country_df[\"cumulative_upper\"].replace(0, np.nan)\n",
    "    \n",
    "    country_df[\"cumulative_under\"] = np.cumsum(country_df[\"under\"].values)\n",
    "    country_df[\"cumulative_under\"] = country_df[\"cumulative_under\"].replace(0, np.nan)\n",
    "    \n",
    "    \n",
    "    cumulative_count_max = country_df[\"cumulative_count\"].max()\n",
    "    \n",
    "    country_df[\"change\"] = country_df[\"count\"] / cumulative_count_max\n",
    "    \n",
    "    country_df[\"change_upper\"] = country_df[\"upper\"] / cumulative_count_max\n",
    "    country_df[\"change_under\"] = country_df[\"under\"] / cumulative_count_max\n",
    "    \n",
    "\n",
    "    dc_roc_df = dc_roc_df.append(country_df, ignore_index=True)\n",
    "dc_roc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of normalized change and country cumulative counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_roc_df = dc_roc_df.loc[(dc_roc_df[\"date\"] >= min_date) & (dc_roc_df[\"date\"] <= max_date)]\n",
    "jhu_roc_df = jhu_roc_df.loc[(jhu_roc_df[\"date\"] >= min_date) & (jhu_roc_df[\"date\"] <= max_date)]\n",
    "\n",
    "color_scale = alt.Scale(domain=list(country_color_map.keys()), range=list(country_color_map.values()))\n",
    "\n",
    "country_selection = alt.selection_multi(fields=[\"country\"], bind=\"legend\")\n",
    "country = alt.condition(country_selection, alt.Color(\"country:N\", scale=color_scale, legend=alt.Legend(title=\"Country\")), alt.value(\"#EAEAEA\"))\n",
    "\n",
    "date_domain = [alt.DateTime(year=min_date.year, month=min_date.month, date=min_date.day), alt.DateTime(year=max_date.year, month=max_date.month, date=max_date.day)]\n",
    "date_scale = alt.X(\"date:T\", scale=alt.Scale(domain=date_domain), title=\"Date\")\n",
    "\n",
    "\n",
    "pct_domain = [0.0, 0.25]\n",
    "count_domain = [1, 1000000]\n",
    "\n",
    "plot = (\n",
    "    (\n",
    "        (\n",
    "            alt.Chart(dc_roc_df)\n",
    "                .mark_line()\n",
    "                .encode(\n",
    "                    x=date_scale,\n",
    "                    y=alt.Y(\"change:Q\", scale=alt.Scale(domain=pct_domain), title=\"Normalized Change\"),\n",
    "                    color=country\n",
    "                )\n",
    "                .properties(title=\"Rate of Change per Country (4CE)\")\n",
    "            +\n",
    "            alt.Chart(dc_roc_df)\n",
    "                .mark_errorband()\n",
    "                .encode(\n",
    "                    x=date_scale,\n",
    "                    y=alt.Y(\"change_upper:Q\", scale=alt.Scale(domain=pct_domain), title=\"Normalized Change\"), \n",
    "                    y2=\"change_under:Q\",\n",
    "                    color=country\n",
    "                )\n",
    "        ).resolve_scale(y=\"shared\").interactive()\n",
    "    | \n",
    "        (\n",
    "            alt.Chart(dc_roc_df)\n",
    "                .mark_line()\n",
    "                .encode(\n",
    "                    x=date_scale,\n",
    "                    y=alt.Y(\"cumulative_count:Q\", scale=alt.Scale(type=\"log\", domain=count_domain), title=\"Cumulative Count\"),\n",
    "                    color=country\n",
    "                )\n",
    "                .properties(title=\"Country Cumulative Counts (4CE)\")   \n",
    "            +\n",
    "            alt.Chart(dc_roc_df)\n",
    "                .mark_errorband()\n",
    "                .encode(\n",
    "                    x=date_scale,\n",
    "                    y=alt.Y(\"cumulative_upper:Q\", scale=alt.Scale(type=\"log\", domain=count_domain), title=\"Cumulative Count\"), \n",
    "                    y2=\"cumulative_under:Q\",\n",
    "                    color=country\n",
    "                )   \n",
    "        ).resolve_scale(color=\"shared\", y=\"shared\", x=\"shared\")\n",
    "    ) & (\n",
    "    alt.Chart(jhu_roc_df)\n",
    "        .mark_line()\n",
    "        .encode(\n",
    "            x=date_scale,\n",
    "            y=alt.Y(\"change:Q\", scale=alt.Scale(domain=pct_domain), title=\"Normalized Change\"),\n",
    "            color=country\n",
    "        )\n",
    "        .properties(title=\"Rate of Change per Country (JHU)\")\n",
    "     | alt.Chart(jhu_roc_df)\n",
    "        .mark_line()\n",
    "        .encode(\n",
    "            x=date_scale,\n",
    "            y=alt.Y(\"cumulative_count:Q\", scale=alt.Scale(type=\"log\", domain=count_domain), title=\"Cumulative Count\"),\n",
    "            color=country\n",
    "        )\n",
    "        .properties(title=\"Country Cumulative Counts (JHU)\")\n",
    "    )\n",
    ").add_selection(\n",
    "    country_selection\n",
    ")\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data for plots faceted by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_roc_df = jhu_roc_df.copy()\n",
    "dc_roc_df = dc_roc_df.copy()\n",
    "jhu_roc_df[\"source\"] = \"JHU CSSE\"\n",
    "dc_roc_df[\"source\"] = \"4CE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_roc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_roc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df = jhu_roc_df.append(dc_roc_df, ignore_index=True)\n",
    "join_df[\"country_source\"] = join_df.apply(lambda row: row[\"country\"] + \"_\" + row[\"source\"], axis='columns')\n",
    "join_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of normalized change faceted by country, with number of sites data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"New Positive Cases, Change by Country, Comparison to JHU CSSE Data\"\n",
    "\n",
    "source_selection = alt.selection_multi(fields=[\"source\"], bind=\"legend\")\n",
    "\n",
    "date_domain = [alt.DateTime(year=min_date.year, month=min_date.month, date=min_date.day), alt.DateTime(year=max_date.year, month=max_date.month, date=max_date.day)]\n",
    "\n",
    "sites_domain = [0, dc_roc_df[\"num_sites\"].max()]\n",
    "\n",
    "country_names = list(country_color_map.keys())\n",
    "country_source_names = [c + \"_\" + \"4CE\" for c in country_names] + [c + \"_\" + \"JHU CSSE\" for c in country_names]\n",
    "color_scale = alt.Scale(domain=country_names, range=list(country_color_map.values()))\n",
    "join_color_scale = alt.Scale(domain=country_source_names, range=list(country_color_map.values()) + [\"#707070\"]*len(country_names))\n",
    "\n",
    "country_width = 170\n",
    "\n",
    "date_brush = alt.selection(type='interval', encodings=['x'], bind=\"scales\")\n",
    "\n",
    "plot = (((alt.Chart(join_df)\n",
    "    .transform_filter(source_selection)\n",
    "    .transform_filter(date_brush)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        x=alt.X(\"date:T\", title=None, axis=alt.Axis(labelBound=True)),\n",
    "        y=alt.Y(\"change:Q\", axis=alt.Axis(title=\"Normalized Change\"), scale=alt.Scale(domain=[0.0, 0.25])),\n",
    "        strokeDash=alt.StrokeDash(\"source:N\", scale=alt.Scale(domain=[\"4CE\", \"JHU CSSE\"], range=[[0,0], [3,3]]), legend=alt.Legend(title=\"Data Source\")),\n",
    "        color=alt.Color(\"country_source:N\", scale=join_color_scale, legend=None)\n",
    "    )\n",
    "    .add_selection(date_brush)\n",
    "    .properties(width=country_width, height=200)\n",
    "    .facet(\n",
    "        column=alt.Column(\"country:N\", header=alt.Header(labelFontSize=14)), bounds=\"flush\"\n",
    "    )\n",
    ") & (alt.Chart(dc_roc_df)\n",
    "        .transform_filter(date_brush)\n",
    "        .mark_bar()\n",
    "        .encode(\n",
    "            x=alt.X(\"date:T\", scale=alt.Scale(domain=date_domain), title=\"Date\", axis=alt.Axis(labelBound=True)),\n",
    "            y=alt.Y(\"num_sites:Q\", axis=alt.Axis(title=\"# of Sites\"), scale=alt.Scale(domain=sites_domain)),\n",
    "            color=alt.Color(\"country:N\", scale=color_scale, legend=None)\n",
    "        )\n",
    "    .add_selection(date_brush)\n",
    "    .properties(width=country_width, height=60)\n",
    "    .facet(\n",
    "        column=alt.Column(\"country:N\", header=alt.Header(labels=False)), bounds=\"flush\"\n",
    "    )\n",
    "))\n",
    ".resolve_scale(color=\"shared\", x=\"shared\")\n",
    ".properties(title={\n",
    "        \"text\": title, \n",
    "        \"subtitle\": SUBTITLE,\n",
    "        \"subtitleColor\": \"gray\",\n",
    "        \"dx\": 60\n",
    "})\n",
    ".add_selection(source_selection)\n",
    ")\n",
    "\n",
    "plot = (apply_theme(plot, axis_label_font_size=10, axis_title_font_size=12, axis_title_padding=8, legend_orient=\"bottom\", legend_symbol_type=\"stroke\")\n",
    "    .configure_header(title=None, labelPadding=3))\n",
    "\n",
    "for_website(plot, \"Daily Count\", \"Normalized change by country\")\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
